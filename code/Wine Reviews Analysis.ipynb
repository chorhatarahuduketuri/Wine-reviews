{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import subprocess\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Problem\n",
    "\n",
    "So the problem is 'how do I know if wine is good?'  \n",
    "Specifically, when in a shop looking for something to buy. \n",
    "\n",
    "There are a few ways I could determine this. \n",
    "\n",
    "# The Solution(s)?\n",
    "\n",
    "1. I could do what I did with the other wine related datasets and train a tree model to get which are the ~3-5 most important factors, and what ranges they should lie in. While I think this will work - and I intend to do it - it also tends to always end up focussing on only one particular ordered set of questions with the same answers; country A, variety B, price C, etc. which doesn't tell me anything about good wines from country F (and I assume that country F must have some good wine or other? Additionally, since several of the features are nominal, non-ordinal data, but they have been represented ordinally, decision trees will not be able to select features out of order from their representation, and this will limit the usefulness of the trained models regardless of how accurate they are. \n",
    "\n",
    "2. I could use some sort of relatively simple model (e.g. linear regression) and try to determine from the coefficients what features are important, and what values are better, but attempts to determine feature relevance in that way usually fail, as coefficients do not correlate with feature importance. I could use some sort of feature selection to further reduce the number of features I have, and make the result easier to understand somehow? The effectiveness of that is unclear, but unlikely. Then again, [scikit-learn's `SelectFromModel`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html \"scikit-learn docs\") exists to do just that - automatically - so maybe that's worth a look. This still doesn't actually tell me what _values_ of features mean good wine though, so I probably won't do this. \n",
    "\n",
    "3. I could train an accurate, black box model that classifies wine, then put that model into a phone app, and use it to give me a likely score (or range of scores) when I manually enter the features of the wine I am looking at on the shelf. The more data I enter, the more accurate the score. This seems like an approach that will provide an actual, physical solution to my problem, but will require a lot more work. \n",
    "\n",
    "# The Plan\n",
    "\n",
    "The first thing I'm going to do is the easiest - solution 1: decision tree models.  \n",
    "Of course the _zeroth_ thing I'm going to do is load and preprocess the data. \n",
    "\n",
    "### Modifications from the EDA\n",
    "The EDA was more about getting to know the data, finding out what was _feasibly physically usable_, and seeing how it could be prepared, _without prejudice_ with respect to what will later turn out to be useful (otherwise my assumptions and biases could cause me to discard or inappropriately interpret data). Now I come to the actual task I must reassess from what I've learned, and make new decisions based on _what difference it makes to the objective_, in order to avoid failing to move towards the value I'm working to create. \n",
    "\n",
    "At this point I have 10 features: \n",
    "1. country\n",
    "2. price\n",
    "3. province\n",
    "4. region_1\n",
    "5. region_2\n",
    "6. taster_name\n",
    "7. taster_twitter_handle\n",
    "8. variety\n",
    "9. winery\n",
    "10. vintage\n",
    "\n",
    "I am trying to find a way to determine the best (or a decent choice of) wine to buy when standing in a shop. That means that the only information I have available to me is what's on the bottle - if I was the type to google it or if I had an interest in learning about wine theory, I wouldn't need to be doing this project - so I should only use features that represent data I can get from the bottle. \n",
    "\n",
    "6. ~~taster_name~~\n",
    "7. ~~taster_twitter_handle~~\n",
    "\n",
    "That means taster_name and taster_twitter_handle are out because - again - if I was going to put in effort to learn wine theory and read reviews, I wouldn't need to be putting my effort towards this project. \n",
    "\n",
    "The country is always available, as is the price (though I will have to be mindful to remember currency conversions when not in the USA). The province is usually available, as is the data that makes up region_1 and region_2. The variety, winery, and vintage are also usually available for all but the cheapest of wines (the mixes and generic 'red wine'). \n",
    "\n",
    "So I end up with 8 features, which I will now begin work with: \n",
    "1. country\n",
    "2. price\n",
    "3. province\n",
    "4. region_1\n",
    "5. region_2\n",
    "6. variety\n",
    "7. winery\n",
    "8. vintage\n",
    "\n",
    "# Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inital data loading \n",
    "data = pd.read_csv('../input/wine-reviews/winemag-data-130k-v2.csv', index_col=0)\n",
    "target_data = data['points']\n",
    "feature_data = data.drop('points', axis=1)\n",
    "\n",
    "# Creation of new feature 'vintage'\n",
    "titles = feature_data.title.copy(deep=True)\n",
    "years = titles.replace(r'.*((19|20)[0-9]{2}).*', r'\\1', regex=True).replace(r'[A-Za-z]|[\\D]|\\s|(?:(?<!\\d)\\d{1}(?!\\d))|(?:(?<!\\d)\\d{2}(?!\\d))|(?:(?<!\\d)\\d{3}(?!\\d))', '', regex=True)\n",
    "filtered_years = years.replace(r'(1503|1607|1821|1827|1847|1868|1872|1868|1872|1882|1887|2067)', '', regex=True)\n",
    "vintage = filtered_years\n",
    "\n",
    "# Removal of unusable features (I can't find the reviewers description \n",
    "# on the bottle, can I?) and addition of new feature 'vintage'\n",
    "raw_reduced_features = feature_data.drop(labels=['description', 'designation', 'title', 'taster_name', 'taster_twitter_handle'], axis=1)\n",
    "raw_reduced_features['vintage'] = vintage.copy(deep=False).replace('', '0').astype(int )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate out all the features so I can transform them individually, \n",
    "# and then put them back together into different datasets\n",
    "country = raw_reduced_features.country.copy(deep=False)\n",
    "price = raw_reduced_features.price.copy(deep=False)\n",
    "province = raw_reduced_features.province.copy(deep=False)\n",
    "region_1 = raw_reduced_features.region_1.copy(deep=False)\n",
    "region_2 = raw_reduced_features.region_2.copy(deep=False)\n",
    "variety = raw_reduced_features.variety.copy(deep=False)\n",
    "winery = raw_reduced_features.winery.copy(deep=False)\n",
    "vintage = raw_reduced_features.vintage.copy(deep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with null values and preparing features for encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all null data to either 0 or the string 'NaN' so that the encoders can process them \n",
    "country[country.isna()] = 'NaN'\n",
    "price[price.isna()] = 0\n",
    "province[province.isna()] = 'NaN'\n",
    "region_1[region_1.isna()] = 'NaN'\n",
    "region_2[region_2.isna()] = 'NaN'\n",
    "variety[variety.isna()] = 'NaN'\n",
    "# winery has no missing values\n",
    "# vintage has already had it's missing data replaced with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows left with no null values after dropping region_2: 129971\n"
     ]
    }
   ],
   "source": [
    "reduced_features_non_null_data = raw_reduced_features.dropna(subset=['country', 'price', 'province', 'region_1', 'region_2', 'variety', 'winery'], axis='index', how='any').copy(deep=False)\n",
    "print('Number of rows left with no null values after dropping region_2: {}'.format(reduced_features_non_null_data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate out all the features so I can transform them individually, \n",
    "# and then put them back together into different datasets\n",
    "country_non_null = reduced_features_non_null_data.country\n",
    "price_non_null = reduced_features_non_null_data.price\n",
    "province_non_null = reduced_features_non_null_data.province\n",
    "region_1_non_null = reduced_features_non_null_data.region_1\n",
    "region_2_non_null = reduced_features_non_null_data.region_2\n",
    "variety_non_null = reduced_features_non_null_data.variety\n",
    "winery_non_null = reduced_features_non_null_data.winery\n",
    "vintage_non_null = reduced_features_non_null_data.vintage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinal numerical encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# country\n",
    "# nulls\n",
    "label_encoder_country = LabelEncoder()\n",
    "label_encoder_country.fit(country.astype(str))\n",
    "encoded_countries = label_encoder_country.transform(country.astype(str))\n",
    "\n",
    "# non-nulls\n",
    "label_encoder_non_null_country = LabelEncoder()\n",
    "label_encoder_non_null_country.fit(country_non_null.astype(str))\n",
    "encoded_non_null_countries = label_encoder_non_null_country.transform(country_non_null.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# province\n",
    "# nulls\n",
    "label_encoder_province = LabelEncoder()\n",
    "label_encoder_province.fit(province.astype(str))\n",
    "encoded_provinces = label_encoder_province.transform(province.astype(str))\n",
    "\n",
    "# non-nulls\n",
    "label_encoder_non_null_province = LabelEncoder()\n",
    "label_encoder_non_null_province.fit(province_non_null.astype(str))\n",
    "encoded_non_null_provinces = label_encoder_non_null_province.transform(province_non_null.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region_1\n",
    "# nulls\n",
    "label_encoder_region_1 = LabelEncoder()\n",
    "label_encoder_region_1.fit(region_1.astype(str))\n",
    "encoded_region_1s = label_encoder_region_1.transform(region_1.astype(str))\n",
    "\n",
    "# non-nulls\n",
    "label_encoder_non_null_region_1 = LabelEncoder()\n",
    "label_encoder_non_null_region_1.fit(region_1_non_null.astype(str))\n",
    "encoded_non_null_region_1s = label_encoder_non_null_region_1.transform(region_1_non_null.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region_2\n",
    "# nulls\n",
    "label_encoder_region_2 = LabelEncoder()\n",
    "label_encoder_region_2.fit(region_2.astype(str))\n",
    "encoded_region_2s = label_encoder_region_2.transform(region_2.astype(str))\n",
    "\n",
    "# non-nulls\n",
    "label_encoder_non_null_region_2 = LabelEncoder()\n",
    "label_encoder_non_null_region_2.fit(region_2_non_null.astype(str))\n",
    "encoded_non_null_region_2s = label_encoder_non_null_region_2.transform(region_2_non_null.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variety\n",
    "# nulls\n",
    "label_encoder_variety = LabelEncoder()\n",
    "label_encoder_variety.fit(variety.astype(str))\n",
    "encoded_varieties = label_encoder_variety.transform(variety.astype(str))\n",
    "\n",
    "# non-nulls\n",
    "label_encoder_non_null_variety = LabelEncoder()\n",
    "label_encoder_non_null_variety.fit(variety_non_null.astype(str))\n",
    "encoded_non_null_varieties = label_encoder_non_null_variety.transform(variety_non_null.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# winery\n",
    "# nulls\n",
    "label_encoder_winery = LabelEncoder()\n",
    "label_encoder_winery.fit(winery.astype(str))\n",
    "encoded_wineries = label_encoder_winery.transform(winery.astype(str))\n",
    "\n",
    "# non-nulls\n",
    "label_encoder_non_null_winery = LabelEncoder()\n",
    "label_encoder_non_null_winery.fit(winery_non_null.astype(str))\n",
    "encoded_non_null_wineries = label_encoder_non_null_winery.transform(winery_non_null.astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# country\n",
    "# nulls\n",
    "one_hot_country = OneHotEncoder(sparse=False)\n",
    "one_hot_country.fit(country.astype(str).values.reshape(-1,1))\n",
    "one_hot_countries = one_hot_country.transform(country.astype(str).values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region_2\n",
    "one_hot_region_2 = OneHotEncoder(sparse=False)\n",
    "one_hot_region_2.fit(region_2.astype(str).values.reshape(-1,1))\n",
    "one_hot_region_2s = one_hot_region_2.transform(region_2.astype(str).values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoded feature data that contains nulls\n",
    "feature_data_label_encoded = raw_reduced_features.copy(deep=False)\n",
    "feature_data_label_encoded['vintage'] = vintage\n",
    "\n",
    "feature_data_label_encoded.country = encoded_countries\n",
    "feature_data_label_encoded.province = encoded_provinces\n",
    "feature_data_label_encoded.region_1 = encoded_region_1s\n",
    "feature_data_label_encoded.region_2 = encoded_region_2s\n",
    "feature_data_label_encoded.variety = encoded_varieties\n",
    "feature_data_label_encoded.winery = encoded_wineries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoded feature data that does not contain nulls\n",
    "feature_data_label_encoded_non_null = reduced_features_non_null_data.copy(deep=False)\n",
    "feature_data_label_encoded_non_null['vintage'] = vintage\n",
    "\n",
    "feature_data_label_encoded_non_null.country = encoded_non_null_countries\n",
    "feature_data_label_encoded_non_null.province = encoded_non_null_provinces\n",
    "feature_data_label_encoded_non_null.region_1 = encoded_non_null_region_1s\n",
    "feature_data_label_encoded_non_null.region_2 = encoded_non_null_region_2s\n",
    "feature_data_label_encoded_non_null.variety = encoded_non_null_varieties\n",
    "feature_data_label_encoded_non_null.winery = encoded_non_null_wineries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixed encoding feature data\n",
    "feature_data_mixed_encoding = raw_reduced_features.copy(deep=False)\n",
    "feature_data_mixed_encoding = feature_data_mixed_encoding.drop(labels=['country', 'region_2'], axis=1)\n",
    "feature_data_mixed_encoding['vintage'] = vintage\n",
    "\n",
    "# Label encoding\n",
    "feature_data_mixed_encoding.province = encoded_provinces\n",
    "feature_data_mixed_encoding.region_1 = encoded_region_1s\n",
    "feature_data_mixed_encoding.variety = encoded_varieties\n",
    "feature_data_mixed_encoding.winery = encoded_wineries\n",
    "\n",
    "# One hot encoding\n",
    "one_hot_countries_df = pd.DataFrame(data=one_hot_countries, columns=one_hot_country.categories_[0])\n",
    "one_hot_countries_df = one_hot_countries_df.rename(columns={\"nan\":\"country_nan\"})\n",
    "feature_data_mixed_encoding = pd.concat([feature_data_mixed_encoding, one_hot_countries_df], axis=1)\n",
    "\n",
    "one_hot_region_2s_df = pd.DataFrame(data=one_hot_region_2s, columns=one_hot_region_2.categories_[0])\n",
    "one_hot_region_2s_df = one_hot_region_2s_df.rename(columns={\"nan\":\"region_2_nan\"})\n",
    "feature_data_mixed_encoding = pd.concat([feature_data_mixed_encoding, one_hot_region_2s_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_data_label_encoded.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test/train splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoded full data test train split\n",
    "X_train_label_encoded, X_test_label_encoded, y_train_label_encoded, y_test_label_encoded = train_test_split(feature_data_label_encoded, target_data, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoded non-null data test train split\n",
    "target_data_non_null = target_data[feature_data_label_encoded_non_null.index]\n",
    "X_train_label_encoded_non_null, X_test_label_encoded_non_null, y_train_label_encoded_non_null, y_test_label_encoded_non_null = train_test_split(feature_data_label_encoded_non_null, target_data_non_null, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixed encoding full data test train split\n",
    "X_train_mixed_encoding, X_test_mixed_encoding, y_train_mixed_encoding, y_test_mixed_encoding = train_test_split(feature_data_mixed_encoding, target_data, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardisation of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoded data standardisation\n",
    "label_encoded_standard_scaler = StandardScaler()\n",
    "label_encoded_standard_scaler.fit(X_train_label_encoded)\n",
    "\n",
    "X_train_label_encoded_standardised = label_encoded_standard_scaler.transform(X_train_label_encoded)\n",
    "X_test_label_encoded_standardised = label_encoded_standard_scaler.transform(X_test_label_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoded non-null data standardisation\n",
    "label_encoded_non_null_standard_scaler = StandardScaler()\n",
    "label_encoded_non_null_standard_scaler.fit(X_train_label_encoded_non_null)\n",
    "\n",
    "X_train_label_encoded_non_null_standardised = label_encoded_non_null_standard_scaler.transform(X_train_label_encoded_non_null)\n",
    "X_test_label_encoded_non_null_standardised = label_encoded_non_null_standard_scaler.transform(X_test_label_encoded_non_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixed encoding full data standardisation\n",
    "mixed_encoding_standard_scaler = StandardScaler()\n",
    "mixed_encoding_standard_scaler.fit(X_train_mixed_encoding)\n",
    "\n",
    "X_train_mixed_encoding_standardised = mixed_encoding_standard_scaler.transform(X_train_mixed_encoding)\n",
    "X_test_mixed_encoding_standardised = mixed_encoding_standard_scaler.transform(X_test_mixed_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 1\n",
    "Decision trees - let's see what they tell me. \n",
    "\n",
    "Since I've already decided on the limited usefulness of decision tree models for this, I'll keep it short and bake in a few assumptions. \n",
    "1. The maximum depth of the tree will not greatly exceed the number of features (8). \n",
    "2. The maximum leaf nodes will not greatly exceed the number of possible scores, rounded to the nearest integer (21). \n",
    "3. I will use Mean Absolute Error as an error metric, as I prefer to when the error metric is easily digestible and especially relevant to the end use of the model's predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 17:14:35.605230\n",
      "DecisionTreeRegressor GridSearchCV label_encoded best score: 0.374080668273635\n",
      "DecisionTreeRegressor GridSearchCV label_encoded best estimator: DecisionTreeRegressor(criterion='mae', max_depth=8, max_features=None,\n",
      "           max_leaf_nodes=39, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=4, splitter='best')\n",
      "\n",
      "\n",
      "DecisionTreeRegressor GridSearchCV label_encoded best estimator test mae: 1.8624319084110423\n",
      "End time: 19:41:56.150086\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'datetime.time' and 'datetime.time'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-3d1b9d39e938>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"End time: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_time_decision_tree_label_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mtime_elapsed_decision_tree_label_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_time_decision_tree_label_encoded\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time_decision_tree_label_encoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Time elapsed: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_elapsed_decision_tree_label_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'datetime.time' and 'datetime.time'"
     ]
    }
   ],
   "source": [
    "# Label encoded decision tree regressor\n",
    "start_time_decision_tree_label_encoded = datetime.datetime.now()\n",
    "print(\"Start time: {}\".format(start_time_decision_tree_label_encoded.time()))\n",
    "\n",
    "label_encoded_params = {\n",
    "    'max_depth': np.arange(3,13,3), \n",
    "    'max_leaf_nodes': np.arange(15,42,3)\n",
    "}\n",
    "\n",
    "label_encoded_gridsearchcv = GridSearchCV(\n",
    "    estimator=DecisionTreeRegressor(criterion='mae', random_state=4), \n",
    "    param_grid=label_encoded_params, \n",
    "    n_jobs=-1, \n",
    "    cv=5)\n",
    "\n",
    "label_encoded_gridsearchcv.fit(X_train_label_encoded_standardised, y_train_label_encoded)\n",
    "print('DecisionTreeRegressor GridSearchCV label_encoded best score: {}'.format(label_encoded_gridsearchcv.best_score_))\n",
    "print('DecisionTreeRegressor GridSearchCV label_encoded best estimator: {}'.format(label_encoded_gridsearchcv.best_estimator_))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('DecisionTreeRegressor GridSearchCV label_encoded best estimator test mae: {}'.format(mean_absolute_error(y_test_label_encoded, label_encoded_gridsearchcv.best_estimator_.predict(X_test_label_encoded_standardised))))\n",
    "\n",
    "end_time_decision_tree_label_encoded = datetime.datetime.now()\n",
    "print(\"End time: {}\".format(end_time_decision_tree_label_encoded.time()))\n",
    "\n",
    "time_elapsed_decision_tree_label_encoded = end_time_decision_tree_label_encoded - start_time_decision_tree_label_encoded\n",
    "print(\"Time elapsed: {}\".format(time_elapsed_decision_tree_label_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save image of label encoded decision tree regressor to output dir\n",
    "export_graphviz(label_encoded_gridsearchcv.best_estimator_, \n",
    "                out_file='label_encoded_gridsearchcv_decisiontreeregressor.dot', \n",
    "                feature_names=feature_data_label_encoded.columns, \n",
    "                label='all', \n",
    "                filled=True, \n",
    "                rounded=True, \n",
    "                leaves_parallel=True, \n",
    "                impurity=True)\n",
    "subprocess.run(['dot', \n",
    "                '-Tpng', \n",
    "                'label_encoded_gridsearchcv_decisiontreeregressor.dot', \n",
    "                '-o', \n",
    "                'label_encoded_gridsearchcv_decisiontreeregressor.png'])\n",
    "subprocess.run(['mv', \n",
    "                'label_encoded_gridsearchcv_decisiontreeregressor.dot', \n",
    "                '../output/label_encoded_gridsearchcv_decisiontreeregressor.dot'])\n",
    "subprocess.run(['mv', \n",
    "                'label_encoded_gridsearchcv_decisiontreeregressor.png', \n",
    "                '../output/label_encoded_gridsearchcv_decisiontreeregressor.png'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoded non null decision tree regressor\n",
    "start_time_decision_tree_non_null = datetime.datetime.now()\n",
    "print(\"Start time: {}\".format(start_time_decision_tree_non_null.time()))\n",
    "\n",
    "label_encoded_non_null_params = {\n",
    "    'max_depth': np.arange(3,13,3), \n",
    "    'max_leaf_nodes': np.arange(15,42,3)\n",
    "}\n",
    "\n",
    "label_encoded_non_null_gridsearchcv = GridSearchCV(\n",
    "    estimator=DecisionTreeRegressor(criterion='mae', random_state=4), \n",
    "    param_grid=label_encoded_non_null_params, \n",
    "    n_jobs=-1, \n",
    "    cv=5)\n",
    "\n",
    "label_encoded_non_null_gridsearchcv.fit(X_train_label_encoded_non_null_standardised, y_train_label_encoded_non_null)\n",
    "print('DecisionTreeRegressor GridSearchCV label_encoded_non_null best score: {}'.format(label_encoded_non_null_gridsearchcv.best_score_))\n",
    "print('DecisionTreeRegressor GridSearchCV label_encoded_non_null best estimator: {}'.format(label_encoded_non_null_gridsearchcv.best_estimator_))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('DecisionTreeRegressor GridSearchCV label_encoded_non_null best estimator test mae: {}'.format(mean_absolute_error(y_test_label_encoded_non_null, label_encoded_non_null_gridsearchcv.best_estimator_.predict(X_test_label_encoded_non_null_standardised))))\n",
    "\n",
    "end_time_decision_tree_non_null = datetime.datetime.now()\n",
    "print(\"End time: {}\".format(end_time_decision_tree_non_null.time()))\n",
    "\n",
    "time_elapsed_decision_tree_non_null = end_time_decision_tree_non_null - start_time_decision_tree_non_null\n",
    "print(\"Time elapsed: {}\".format(time_elapsed_decision_tree_non_null))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save image of label encoded non null decision tree regressor to output dir\n",
    "export_graphviz(label_encoded_non_null_gridsearchcv.best_estimator_, \n",
    "                out_file='label_encoded_non_null_gridsearchcv_decisiontreeregressor.dot', \n",
    "                feature_names=feature_data_label_encoded_non_null.columns, \n",
    "                label='all', \n",
    "                filled=True, \n",
    "                rounded=True, \n",
    "                leaves_parallel=True, \n",
    "                impurity=True)\n",
    "subprocess.run(['dot', \n",
    "                '-Tpng', \n",
    "                'label_encoded_non_null_gridsearchcv_decisiontreeregressor.dot', \n",
    "                '-o', \n",
    "                'label_encoded_non_null_gridsearchcv_decisiontreeregressor.png'])\n",
    "subprocess.run(['mv', \n",
    "                'label_encoded_non_null_gridsearchcv_decisiontreeregressor.dot', \n",
    "                '../output/label_encoded_non_null_gridsearchcv_decisiontreeregressor.dot'])\n",
    "subprocess.run(['mv', \n",
    "                'label_encoded_non_null_gridsearchcv_decisiontreeregressor.png', \n",
    "                '../output/label_encoded_non_null_gridsearchcv_decisiontreeregressor.png'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixed encoding non null decision tree regressor\n",
    "start_time_decision_tree_mixed_encoding = datetime.datetime.now()\n",
    "print(\"Start time: {}\".format(start_time_decision_tree_mixed_encoding.time()))\n",
    "\n",
    "mixed_encoding_params = {\n",
    "    'max_depth': np.arange(3,13,3), \n",
    "    'max_leaf_nodes': np.arange(15,42,3)\n",
    "}\n",
    "\n",
    "mixed_encoding_gridsearchcv = GridSearchCV(\n",
    "    estimator=DecisionTreeRegressor(criterion='mae', random_state=4), \n",
    "    param_grid=mixed_encoding_params, \n",
    "    n_jobs=-1, \n",
    "    cv=5)\n",
    "\n",
    "mixed_encoding_gridsearchcv.fit(X_train_mixed_encoding_standardised, y_train_mixed_encoding)\n",
    "print('DecisionTreeRegressor GridSearchCV mixed_encoding best score: {}'.format(mixed_encoding_gridsearchcv.best_score_))\n",
    "print('DecisionTreeRegressor GridSearchCV mixed_encoding best estimator: {}'.format(mixed_encoding_gridsearchcv.best_estimator_))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('DecisionTreeRegressor GridSearchCV mixed_encoding best estimator test mae: {}'.format(mean_absolute_error(y_test_mixed_encoding, mixed_encoding_gridsearchcv.best_estimator_.predict(X_test_mixed_encoding_standardised))))\n",
    "\n",
    "end_time_decision_tree_mixed_encoding = datetime.datetime.now()\n",
    "print(\"End time: {}\".format(end_time_decision_tree_mixed_encoding.time()))\n",
    "\n",
    "time_elapsed_decision_tree_mixed_encoding = end_time_decision_tree_mixed_encoding - start_time_decision_tree_mixed_encoding\n",
    "print(\"Time elapsed: {}\".format(time_elapsed_decision_tree_mixed_encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save image of mixed encoding decision tree regressor to output dir\n",
    "export_graphviz(mixed_encoding_gridsearchcv.best_estimator_, \n",
    "                out_file='mixed_encoding_gridsearchcv_decisiontreeregressor.dot', \n",
    "                feature_names=feature_data_mixed_encoding.columns, \n",
    "                label='all', \n",
    "                filled=True, \n",
    "                rounded=True, \n",
    "                leaves_parallel=True, \n",
    "                impurity=True)\n",
    "subprocess.run(['dot', \n",
    "                '-Tpng', \n",
    "                'mixed_encoding_gridsearchcv_decisiontreeregressor.dot', \n",
    "                '-o', \n",
    "                'mixed_encoding_gridsearchcv_decisiontreeregressor.png'])\n",
    "subprocess.run(['mv', \n",
    "                'mixed_encoding_gridsearchcv_decisiontreeregressor.dot', \n",
    "                '../output/mixed_encoding_gridsearchcv_decisiontreeregressor.dot'])\n",
    "subprocess.run(['mv', \n",
    "                'mixed_encoding_gridsearchcv_decisiontreeregressor.png', \n",
    "                '../output/mixed_encoding_gridsearchcv_decisiontreeregressor.png'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![label_encoded_non_null_gridsearchcv_decisiontreeregressor](../output/label_encoded_non_null_gridsearchcv_decisiontreeregressor.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(datetime.datetime.now())\n",
    "# dtr = DecisionTreeRegressor(criterion='mae', max_depth=7, max_features=1, max_leaf_nodes=21, random_state=4)\n",
    "\n",
    "# dtr.fit(X_train_label_encoded_non_null, y_train_label_encoded_non_null)\n",
    "\n",
    "# preds = dtr.predict(X_test_label_encoded_non_null)\n",
    "\n",
    "# mae = mean_absolute_error(y_test_label_encoded_non_null, preds)\n",
    "# mae\n",
    "# print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export_graphviz(dtr, out_file='dtr_test.dot', \n",
    "#                 feature_names=feature_data_label_encoded_non_null.columns, \n",
    "#                 label='all',\n",
    "#                 filled=True,\n",
    "#                 rounded=True,\n",
    "#                 leaves_parallel=True,\n",
    "#                 impurity=True)\n",
    "# subprocess.run(['dot','-Tpng', 'dtr_test.dot', '-o', 'dtr_test.png'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dtr_test](dtr_test.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 2\n",
    "Linear regression. \n",
    "\n",
    "Again, I'll use mean absolute error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 19:54:15.690759\n",
      "Linear regression label_encoded test mae: 2.2236270134283433\n",
      "End time: 19:54:15.731479\n",
      "Time elapsed: 0:00:00.040720\n"
     ]
    }
   ],
   "source": [
    "# Label encoded linear regression\n",
    "start_time_linear_regression_label_encoded = datetime.datetime.now()\n",
    "print(\"Start time: {}\".format(start_time_linear_regression_label_encoded.time()))\n",
    "\n",
    "# There are no parameters to set, so GridSearchCV is unnecessary\n",
    "label_encoded_linear_regression = LinearRegression()\n",
    "label_encoded_linear_regression.fit(X_train_label_encoded_standardised, y_train_label_encoded)\n",
    "\n",
    "print('Linear regression label_encoded test mae: {}'.format(mean_absolute_error(y_test_label_encoded, label_encoded_linear_regression.predict(X_test_label_encoded_standardised))))\n",
    "\n",
    "end_time_linear_regression_label_encoded = datetime.datetime.now()\n",
    "print(\"End time: {}\".format(end_time_linear_regression_label_encoded.time()))\n",
    "\n",
    "time_elapsed_linear_regression_label_encoded = end_time_linear_regression_label_encoded - start_time_linear_regression_label_encoded\n",
    "print(\"Time elapsed: {}\".format(time_elapsed_linear_regression_label_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 19:54:18.178757\n",
      "Linear regression label_encoded_non_null test mae: 2.2236270134283433\n",
      "End time: 19:54:18.212136\n",
      "Time elapsed: 0:00:00.033379\n"
     ]
    }
   ],
   "source": [
    "# Label encoded non null linear regression\n",
    "start_time_linear_regression_label_encoded_non_null = datetime.datetime.now()\n",
    "print(\"Start time: {}\".format(start_time_linear_regression_label_encoded_non_null.time()))\n",
    "\n",
    "# There are no parameters to set, so GridSearchCV is unnecessary\n",
    "label_encoded_non_null_linear_regression = LinearRegression()\n",
    "label_encoded_non_null_linear_regression.fit(X_train_label_encoded_non_null_standardised, y_train_label_encoded_non_null)\n",
    "\n",
    "print('Linear regression label_encoded_non_null test mae: {}'.format(mean_absolute_error(y_test_label_encoded_non_null, label_encoded_non_null_linear_regression.predict(X_test_label_encoded_non_null_standardised))))\n",
    "\n",
    "end_time_linear_regression_label_encoded_non_null = datetime.datetime.now()\n",
    "print(\"End time: {}\".format(end_time_linear_regression_label_encoded_non_null.time()))\n",
    "\n",
    "time_elapsed_linear_regression_label_encoded_non_null = end_time_linear_regression_label_encoded_non_null - start_time_linear_regression_label_encoded_non_null\n",
    "print(\"Time elapsed: {}\".format(time_elapsed_linear_regression_label_encoded_non_null))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 19:54:20.260816\n",
      "Linear regression mixed_encoding test mae: 31901654.235031657\n",
      "End time: 19:54:20.865510\n",
      "Time elapsed: 0:00:00.604694\n"
     ]
    }
   ],
   "source": [
    "# Label encoded linear regression\n",
    "start_time_linear_regression_mixed_encoding = datetime.datetime.now()\n",
    "print(\"Start time: {}\".format(start_time_linear_regression_mixed_encoding.time()))\n",
    "\n",
    "# There are no parameters to set, so GridSearchCV is unnecessary\n",
    "mixed_encoding_linear_regression = LinearRegression()\n",
    "mixed_encoding_linear_regression.fit(X_train_mixed_encoding_standardised, y_train_mixed_encoding)\n",
    "\n",
    "print('Linear regression mixed_encoding test mae: {}'.format(mean_absolute_error(y_test_mixed_encoding, mixed_encoding_linear_regression.predict(X_test_mixed_encoding_standardised))))\n",
    "\n",
    "end_time_linear_regression_mixed_encoding = datetime.datetime.now()\n",
    "print(\"End time: {}\".format(end_time_linear_regression_mixed_encoding.time()))\n",
    "\n",
    "time_elapsed_linear_regression_mixed_encoding = end_time_linear_regression_mixed_encoding - start_time_linear_regression_mixed_encoding\n",
    "print(\"Time elapsed: {}\".format(time_elapsed_linear_regression_mixed_encoding))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
