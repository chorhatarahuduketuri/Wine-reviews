{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Problem\n",
    "\n",
    "So the problem is 'how do I know if wine is good?'  \n",
    "Specifically, when in a shop looking for something to buy. \n",
    "\n",
    "There are a few ways I could determine this. \n",
    "\n",
    "# The Solution(s)?\n",
    "\n",
    "1. I could do what I did with the other wine related datasets and train a tree model to get which are the ~3-5 most important factors, and what ranges they should lie in. While I think this will work - and I intend to do it - it also tends to always end up focussing on only one particular ordered set of questions with the same answers; country A, variety B, price C, etc. which doesn't tell me anything about good wines from country F (and I assume that country F must have some good wine or other? \n",
    "\n",
    "2. I could use some sort of relatively simple model (e.g. linear regression) and try to determine from the coefficients what features are important, and what values are better, but attempts to determine feature relevance in that way usually fail, as coefficients do not correlate with feature importance. I could use some sort of feature selection to further reduce the number of features I have, and make the result easier to understand somehow? The effectiveness of that is unclear, but unlikely. Then again, [scikit-learn's `SelectFromModel`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html \"scikit-learn docs\") exists to do just that - automatically - so maybe that's worth a look. This still doesn't actually tell me what _values_ of features mean good wine though, so I probably won't do this. \n",
    "\n",
    "3. I could train an accurate, black box model that classifies wine, then put that model into a phone app, and use it to give me a likely score (or range of scores) when I manually enter the features of the wine I am looking at on the shelf. The more data I enter, the more accurate the score. This seems like an approach that will provide an actual, physical solution to my problem, but will require a lot more work. \n",
    "\n",
    "# The Plan\n",
    "\n",
    "The first thing I'm going to do is the easiest - solution 1: decision tree models.  \n",
    "Of course the _zeroth_ thing I'm going to do is load and preprocess the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inital data loading \n",
    "data = pd.read_csv('../input/wine-reviews/winemag-data-130k-v2.csv', index_col=0)\n",
    "target_data = data['points']\n",
    "feature_data = data.drop('points', axis=1)\n",
    "\n",
    "# Creation of new feature 'vintage'\n",
    "titles = feature_data.title.copy(deep=True)\n",
    "years = titles.replace(r'.*((19|20)[0-9]{2}).*', r'\\1', regex=True).replace(r'[A-Za-z]|[\\D]|\\s|(?:(?<!\\d)\\d{1}(?!\\d))|(?:(?<!\\d)\\d{2}(?!\\d))|(?:(?<!\\d)\\d{3}(?!\\d))', '', regex=True)\n",
    "filtered_years = years.replace(r'(1503|1607|1821|1827|1847|1868|1872|1868|1872|1882|1887|2067)', '', regex=True)\n",
    "vintage = filtered_years\n",
    "\n",
    "# Removal of unusable features (I can't find the reviewers description \n",
    "# on the bottle, can I?) and addition of new feature 'vintage'\n",
    "raw_reduced_features = feature_data.drop(labels=['description', 'designation', 'title'], axis=1)\n",
    "raw_reduced_features['vintage'] = vintage.copy(deep=False).replace('', '0').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate out all the features so I can transform them individually, \n",
    "# and then put them back together into different datasets\n",
    "country = raw_reduced_features.country\n",
    "price = raw_reduced_features.price\n",
    "province = raw_reduced_features.province\n",
    "region_1 = raw_reduced_features.region_1\n",
    "region_2 = raw_reduced_features.region_2\n",
    "taster_name = raw_reduced_features.taster_name\n",
    "taster_twitter_handle = raw_reduced_features.taster_twitter_handle\n",
    "variety = raw_reduced_features.variety\n",
    "winery = raw_reduced_features.winery\n",
    "vintage = raw_reduced_features.vintage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['country', 'price', 'province', 'region_1', 'region_2', 'taster_name',\n",
       "       'taster_twitter_handle', 'variety', 'winery', 'vintage'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_reduced_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows left with no null values after dropping region_2 and taster_twitter_handle: 34559\n"
     ]
    }
   ],
   "source": [
    "reduced_features_non_null_data = raw_reduced_features.dropna(subset=['country', 'price', 'province', 'region_1', 'region_2', 'taster_name', 'variety', 'winery'], axis='index', how='any').copy(deep=False)\n",
    "print('Number of rows left with no null values after dropping region_2 and taster_twitter_handle: {}'.format(reduced_features_non_null_data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate out all the features so I can transform them individually, \n",
    "# and then put them back together into different datasets\n",
    "country_non_null = reduced_features_non_null_data.country\n",
    "price_non_null = reduced_features_non_null_data.price\n",
    "province_non_null = reduced_features_non_null_data.province\n",
    "region_1_non_null = reduced_features_non_null_data.region_1\n",
    "region_2_non_null = reduced_features_non_null_data.region_2\n",
    "taster_name_non_null = reduced_features_non_null_data.taster_name\n",
    "taster_twitter_handle_non_null = reduced_features_non_null_data.taster_twitter_handle\n",
    "variety_non_null = reduced_features_non_null_data.variety\n",
    "winery_non_null = reduced_features_non_null_data.winery\n",
    "vintage_non_null = reduced_features_non_null_data.vintage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinal Numerical Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# country\n",
    "# nulls\n",
    "label_encoder_country = LabelEncoder()\n",
    "label_encoder_country.fit(country.astype(str))\n",
    "encoded_countries = label_encoder_country.transform(country.astype(str))\n",
    "\n",
    "# non-nulls\n",
    "label_encoder_non_null_country = LabelEncoder()\n",
    "label_encoder_non_null_country.fit(country_non_null.astype(str))\n",
    "encoded_non_null_countries = label_encoder_non_null_country.transform(country_non_null.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# province\n",
    "# nulls\n",
    "label_encoder_province = LabelEncoder()\n",
    "label_encoder_province.fit(province.astype(str))\n",
    "encoded_provinces = label_encoder_province.transform(province.astype(str))\n",
    "\n",
    "# non-nulls\n",
    "label_encoder_non_null_province = LabelEncoder()\n",
    "label_encoder_non_null_province.fit(province_non_null.astype(str))\n",
    "encoded_non_null_provinces = label_encoder_non_null_province.transform(province_non_null.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region_1\n",
    "# nulls\n",
    "label_encoder_region_1 = LabelEncoder()\n",
    "label_encoder_region_1.fit(region_1.astype(str))\n",
    "encoded_region_1s = label_encoder_region_1.transform(region_1.astype(str))\n",
    "\n",
    "# non-nulls\n",
    "label_encoder_non_null_region_1 = LabelEncoder()\n",
    "label_encoder_non_null_region_1.fit(region_1_non_null.astype(str))\n",
    "encoded_non_null_region_1s = label_encoder_non_null_region_1.transform(region_1_non_null.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region_2\n",
    "# nulls\n",
    "label_encoder_region_2 = LabelEncoder()\n",
    "label_encoder_region_2.fit(region_2.astype(str))\n",
    "encoded_region_2s = label_encoder_region_2.transform(region_2.astype(str))\n",
    "\n",
    "# non-nulls\n",
    "label_encoder_non_null_region_2 = LabelEncoder()\n",
    "label_encoder_non_null_region_2.fit(region_2_non_null.astype(str))\n",
    "encoded_non_null_region_2s = label_encoder_non_null_region_2.transform(region_2_non_null.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taster_name\n",
    "# nulls\n",
    "label_encoder_taster_name = LabelEncoder()\n",
    "label_encoder_taster_name.fit(taster_name.astype(str))\n",
    "encoded_taster_names = label_encoder_taster_name.transform(taster_name.astype(str))\n",
    "\n",
    "# non-nulls\n",
    "label_encoder_non_null_taster_name = LabelEncoder()\n",
    "label_encoder_non_null_taster_name.fit(taster_name_non_null.astype(str))\n",
    "encoded_non_null_taster_names = label_encoder_non_null_taster_name.transform(taster_name_non_null.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taster_twitter_handle\n",
    "# nulls\n",
    "label_encoder_taster_twitter_handle = LabelEncoder()\n",
    "label_encoder_taster_twitter_handle.fit(taster_twitter_handle.astype(str))\n",
    "encoded_taster_twitter_handles = label_encoder_taster_twitter_handle.transform(taster_twitter_handle.astype(str))\n",
    "\n",
    "# non-nulls\n",
    "label_encoder_non_null_taster_twitter_handle = LabelEncoder()\n",
    "label_encoder_non_null_taster_twitter_handle.fit(taster_twitter_handle_non_null.astype(str))\n",
    "encoded_non_null_taster_twitter_handles = label_encoder_non_null_taster_twitter_handle.transform(taster_twitter_handle_non_null.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variety\n",
    "# nulls\n",
    "label_encoder_variety = LabelEncoder()\n",
    "label_encoder_variety.fit(variety.astype(str))\n",
    "encoded_varieties = label_encoder_variety.transform(variety.astype(str))\n",
    "\n",
    "# non-nulls\n",
    "label_encoder_non_null_variety = LabelEncoder()\n",
    "label_encoder_non_null_variety.fit(variety_non_null.astype(str))\n",
    "encoded_non_null_varieties = label_encoder_non_null_variety.transform(variety_non_null.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# winery\n",
    "# nulls\n",
    "label_encoder_winery = LabelEncoder()\n",
    "label_encoder_winery.fit(winery.astype(str))\n",
    "encoded_wineries = label_encoder_winery.transform(winery.astype(str))\n",
    "\n",
    "# non-nulls\n",
    "label_encoder_non_null_winery = LabelEncoder()\n",
    "label_encoder_non_null_winery.fit(winery_non_null.astype(str))\n",
    "encoded_non_null_wineries = label_encoder_non_null_winery.transform(winery_non_null.astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# country\n",
    "# nulls\n",
    "one_hot_country = OneHotEncoder(sparse=False)\n",
    "one_hot_country.fit(country.astype(str).values.reshape(-1,1))\n",
    "one_hot_countries = one_hot_country.transform(country.astype(str).values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region_2\n",
    "one_hot_region_2 = OneHotEncoder(sparse=False)\n",
    "one_hot_region_2.fit(region_2.astype(str).values.reshape(-1,1))\n",
    "one_hot_region_2s = one_hot_region_2.transform(region_2.astype(str).values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taster_name\n",
    "one_hot_taster_name = OneHotEncoder(sparse=False)\n",
    "one_hot_taster_name.fit(taster_name.astype(str).values.reshape(-1,1))\n",
    "one_hot_taster_names = one_hot_taster_name.transform(taster_name.astype(str).values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taster_twitter_handle\n",
    "one_hot_taster_twitter_handle = OneHotEncoder(sparse=False)\n",
    "one_hot_taster_twitter_handle.fit(taster_twitter_handle.astype(str).values.reshape(-1,1))\n",
    "one_hot_taster_twitter_handles = one_hot_taster_twitter_handle.transform(taster_twitter_handle.astype(str).values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoded feature data that contains nulls\n",
    "feature_data_label_encoded = raw_reduced_features.copy(deep=False)\n",
    "feature_data_label_encoded['vintage'] = vintage\n",
    "\n",
    "feature_data_label_encoded.country = encoded_countries\n",
    "feature_data_label_encoded.province = encoded_provinces\n",
    "feature_data_label_encoded.region_1 = encoded_region_1s\n",
    "feature_data_label_encoded.region_2 = encoded_region_2s\n",
    "feature_data_label_encoded.taster_name = encoded_taster_names\n",
    "feature_data_label_encoded.taster_twitter_handle = encoded_taster_twitter_handles\n",
    "feature_data_label_encoded.variety = encoded_varieties\n",
    "feature_data_label_encoded.winery = encoded_wineries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoded feature data that does not contain nulls\n",
    "feature_data_label_encoded_non_null = reduced_features_non_null_data.copy(deep=False)\n",
    "feature_data_label_encoded_non_null['vintage'] = vintage\n",
    "\n",
    "feature_data_label_encoded_non_null.country = encoded_non_null_countries\n",
    "feature_data_label_encoded_non_null.province = encoded_non_null_provinces\n",
    "feature_data_label_encoded_non_null.region_1 = encoded_non_null_region_1s\n",
    "feature_data_label_encoded_non_null.region_2 = encoded_non_null_region_2s\n",
    "feature_data_label_encoded_non_null.taster_name = encoded_non_null_taster_names\n",
    "feature_data_label_encoded_non_null.taster_twitter_handle = encoded_non_null_taster_twitter_handles\n",
    "feature_data_label_encoded_non_null.variety = encoded_non_null_varieties\n",
    "feature_data_label_encoded_non_null.winery = encoded_non_null_wineries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixed encoding feature data\n",
    "feature_data_mixed_encoding = raw_reduced_features.copy(deep=False)\n",
    "feature_data_mixed_encoding = feature_data_mixed_encoding.drop(labels=['country', 'region_2', 'taster_name', 'taster_twitter_handle'], axis=1)\n",
    "feature_data_mixed_encoding['vintage'] = vintage\n",
    "\n",
    "# Label encoding\n",
    "feature_data_mixed_encoding.province = encoded_provinces\n",
    "feature_data_mixed_encoding.region_1 = encoded_region_1s\n",
    "feature_data_mixed_encoding.variety = encoded_varieties\n",
    "feature_data_mixed_encoding.winery = encoded_wineries\n",
    "\n",
    "# One hot encoding\n",
    "one_hot_countries_df = pd.DataFrame(data=one_hot_countries, columns=one_hot_country.categories_[0])\n",
    "one_hot_countries_df = one_hot_countries_df.rename(columns={\"nan\":\"country_nan\"})\n",
    "feature_data_mixed_encoding = pd.concat([feature_data_mixed_encoding, one_hot_countries_df], axis=1)\n",
    "\n",
    "one_hot_region_2s_df = pd.DataFrame(data=one_hot_region_2s, columns=one_hot_region_2.categories_[0])\n",
    "one_hot_region_2s_df = one_hot_region_2s_df.rename(columns={\"nan\":\"region_2_nan\"})\n",
    "feature_data_mixed_encoding = pd.concat([feature_data_mixed_encoding, one_hot_region_2s_df], axis=1)\n",
    "\n",
    "one_hot_taster_names_df = pd.DataFrame(data=one_hot_taster_names, columns=one_hot_taster_name.categories_[0])\n",
    "one_hot_taster_names_df = one_hot_taster_names_df.rename(columns={\"nan\":\"taster_name_nan\"})\n",
    "feature_data_mixed_encoding = pd.concat([feature_data_mixed_encoding, one_hot_taster_names_df], axis=1)\n",
    "\n",
    "one_hot_taster_twitter_handles_df = pd.DataFrame(data=one_hot_taster_twitter_handles, columns=one_hot_taster_twitter_handle.categories_[0])\n",
    "one_hot_taster_twitter_handles_df = one_hot_taster_twitter_handles_df.rename(columns={\"nan\":\"taster_twitter_handle_nan\"})\n",
    "feature_data_mixed_encoding = pd.concat([feature_data_mixed_encoding, one_hot_taster_twitter_handles_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test/Train Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoded full data test train split\n",
    "X_train_label_encoded, X_test_label_encoded, y_train_label_encoded, y_test_label_encoded = train_test_split(feature_data_label_encoded, target_data, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoded non-null data test train split\n",
    "target_data_non_null = target_data[feature_data_label_encoded_non_null.index]\n",
    "X_train_label_encoded_non_null, X_test_label_encoded_non_null, y_train_label_encoded_non_null, y_test_label_encoded_non_null = train_test_split(feature_data_label_encoded_non_null, target_data_non_null, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixed encoding full data test train split\n",
    "X_train_mixed_encoding, X_test_mixed_encoding, y_train_mixed_encoding, y_test_mixed_encoding = train_test_split(feature_data_mixed_encoding, target_data, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardisation of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoded data standardisation\n",
    "label_encoded_standard_scaler = StandardScaler()\n",
    "label_encoded_standard_scaler.fit(X_train_label_encoded)\n",
    "\n",
    "X_train_label_encoded_standardised = label_encoded_standard_scaler.transform(X_train_label_encoded)\n",
    "X_test_label_encoded_standardised = label_encoded_standard_scaler.transform(X_test_label_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoded non-null data standardisation\n",
    "label_encoded_non_null_standard_scaler = StandardScaler()\n",
    "label_encoded_non_null_standard_scaler.fit(X_train_label_encoded_non_null)\n",
    "\n",
    "X_train_label_encoded_non_null_standardised = label_encoded_non_null_standard_scaler.transform(X_train_label_encoded_non_null)\n",
    "X_test_label_encoded_non_null_standardised = label_encoded_non_null_standard_scaler.transform(X_test_label_encoded_non_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixed encoding full data standardisation\n",
    "mixed_encoding_standard_scaler = StandardScaler()\n",
    "mixed_encoding_standard_scaler.fit(X_train_mixed_encoding)\n",
    "\n",
    "X_train_mixed_encoding_standardised = mixed_encoding_standard_scaler.transform(X_train_mixed_encoding)\n",
    "X_test_mixed_encoding_standardised = mixed_encoding_standard_scaler.transform(X_test_mixed_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 1\n",
    "Decision trees - let's see what they tell me. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.024988458163905"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr = DecisionTreeRegressor(max_depth=9, min_samples_split=500, max_features=1, random_state=4)\n",
    "\n",
    "dtr.fit(X_train_label_encoded_non_null, y_train_label_encoded_non_null)\n",
    "\n",
    "preds = dtr.predict(X_test_label_encoded_non_null)\n",
    "\n",
    "mae = mean_absolute_error(y_test_label_encoded_non_null, preds)\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['dot', '-Tpng', 'dtr_test.dot', '-o', 'dtr_test.png'], returncode=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_graphviz(dtr, out_file='dtr_test.dot', \n",
    "                feature_names=feature_data_label_encoded_non_null.columns, \n",
    "                label='all', \n",
    "                filled=True, \n",
    "                rounded=True,\n",
    "                leaves_parallel=True, \n",
    "                impurity=True)\n",
    "subprocess.run(['dot','-Tpng', 'dtr_test.dot', '-o', 'dtr_test.png'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dtr_test](dtr_test.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
